{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "j7g8jMkdLk1p",
        "Q9UQ7bNlLsxh",
        "SxaUfrJ30ui9",
        "LGslvNuwU9LQ",
        "2kaAdOux4r29",
        "euYL88R1oLfg",
        "BBVuWV_bOD4h",
        "h59vlbinSorS",
        "rDkqt-Nk9EeY",
        "2h4eYvwRRBBV",
        "vcgZXpudQ5IH",
        "NsEgfBXI9o7z",
        "xqBmSdvt-OW7",
        "O3zIRa-I1j_x",
        "NM86pnIh_Fgj",
        "bnJ_4Qd9CkIJ",
        "qI2B94c7CG18",
        "zPM_qd2VHma0",
        "p0YojJbw3PHJ",
        "hvBGw_TY3PHL",
        "-lgooUVi3PHM"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/radwaahmed20112000/QA-Chatbot/blob/main/SuperAgent_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing**"
      ],
      "metadata": {
        "id": "TRVgaBD4LbAt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "OQ55uEL75kWA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports\n"
      ],
      "metadata": {
        "id": "j7g8jMkdLk1p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFwY_5F6Tyiz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import os\n",
        "import io\n",
        "import gzip\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "PlqXiQqaWgGi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6432e39-c974-4b12-9a17-393661cc3903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "K._get_available_gpus()"
      ],
      "metadata": {
        "id": "wMjaXyIJjbiL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf428eb7-e8d0-448e-ba1c-14fb9b8235b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/device:GPU:0']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Global Variables"
      ],
      "metadata": {
        "id": "Aw2Vc9JLn_Bw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive_root_path = '/content/drive/My Drive/Colab Notebooks/chatbot project/Chatbot/'\n",
        "test_dev_ratio = 0.2\n",
        "chitchat_train_set = chitchat_dev_set = chitchat_test_set = pd.DataFrame(columns=['question','answer'])\n",
        "categories_train_set, categories_dev_set, categories_test_set = [], [], []"
      ],
      "metadata": {
        "id": "_hOe6a6cnmOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset parsing\n"
      ],
      "metadata": {
        "id": "Q9UQ7bNlLsxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  \n",
        "  for l in g:\n",
        "    yield eval(l)"
      ],
      "metadata": {
        "id": "yd3GxwkLNp9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "    \n",
        "  return pd.DataFrame.from_dict(df, orient='index')"
      ],
      "metadata": {
        "id": "4FIKct3eY7ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean Data"
      ],
      "metadata": {
        "id": "SxaUfrJ30ui9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports\n"
      ],
      "metadata": {
        "id": "Dn5pEaVw13L-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "Ie555-6W16sB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Punctuation Removal"
      ],
      "metadata": {
        "id": "RtWtTJSx01Or"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuation(text):  \n",
        "  return text.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))"
      ],
      "metadata": {
        "id": "-_oGdHPC17_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deconstruction\n"
      ],
      "metadata": {
        "id": "LGslvNuwU9LQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decontracted(phrase):\n",
        "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    return phrase"
      ],
      "metadata": {
        "id": "-GSn2GfqVAx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clean"
      ],
      "metadata": {
        "id": "2kaAdOux4r29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clean_question = lambda x: remove_punctuation(decontracted(x.lower()))\n",
        "clean_answer = lambda x: 'START_ '+ remove_punctuation(decontracted(x.lower())) + ' _END' "
      ],
      "metadata": {
        "id": "-ygBHbne4ExM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data load and Split"
      ],
      "metadata": {
        "id": "euYL88R1oLfg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split"
      ],
      "metadata": {
        "id": "Y9EOgpF35WCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_split(dataset):\n",
        "\n",
        "  dataset = dataset.sample(frac=1, random_state=1).reset_index(drop=True)\n",
        "\n",
        "  train, test = train_test_split(dataset, test_size=test_dev_ratio, \n",
        "                                         random_state=0)\n",
        "\n",
        "  test, dev = train_test_split(test, test_size=0.5, \n",
        "                                         random_state=0) \n",
        "  \n",
        "  return train, dev, test"
      ],
      "metadata": {
        "id": "XILLtYrCTOVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load"
      ],
      "metadata": {
        "id": "CDKWe5lf5ZCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_new_dataset():\n",
        "\n",
        "  global categories_train_set, categories_dev_set, categories_test_set\n",
        "\n",
        "  files = ['qa_1.txt', \n",
        "           'qa_2.txt',\n",
        "           'qa_3.txt',\n",
        "           'WikiQA.tsv']\n",
        "\n",
        "  df = pd.DataFrame(columns=['question','answer'])\n",
        "  for file in files:\n",
        "\n",
        "    data = pd.read_csv(drive_root_path + 'dataset/' + file, sep=\"\\t\",\n",
        "                        encoding = 'unicode_escape')\n",
        "\n",
        "    if file == 'WikiQA.tsv':\n",
        "      data.columns = ['QuestionID', 'question',\t'DocumentID',\t'DocumentTitle', \n",
        "                      'SentenceID', 'answer', 'Label']\n",
        "    else:  \n",
        "      data.columns = ['ArticleTitle', 'question', 'answer', 'diff_q', 'diff_a', \n",
        "                    'ArticleFile']\n",
        "\n",
        "    data = data[['question', 'answer']]\n",
        "\n",
        "    data['question'] = data['question'].values.astype(str)\n",
        "    data['answer'] = data['answer'].values.astype(str)\n",
        "\n",
        "    df = df[df['question'].apply(lambda x: len(x.split()) <= 8)]\n",
        "\n",
        "    data['question'] = data['question'].apply(clean_question)\n",
        "    data['answer']   = data['answer'].apply(clean_answer)\n",
        "\n",
        "    df = pd.concat([df, data])\n",
        "\n",
        "  return data_split(df.head(20000))"
      ],
      "metadata": {
        "id": "oY9LvETYv3FH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_split_amazon_dataset():\n",
        "\n",
        "  global categories_train_set, categories_dev_set, categories_test_set\n",
        "\n",
        "  geners = ['qa_Clothing_Shoes_and_Jewelry.json.gz', \n",
        "            'qa_Health_and_Personal_Care.json.gz',\n",
        "            'qa_Sports_and_Outdoors.json.gz']\n",
        "\n",
        "  for gener in geners:\n",
        "\n",
        "    df = getDF(drive_root_path + gener)\n",
        "\n",
        "    df = df[df['answer'].apply(lambda x: len(x.split()) <= 50)]\n",
        "\n",
        "    df['question'] = df['question'].apply(clean_question)\n",
        "    df['answer']   = df['answer'].apply(clean_answer)    \n",
        "    \n",
        "    train, dev, test = data_split(df[['question', 'answer']])\n",
        "\n",
        "    categories_train_set.append(train)\n",
        "    categories_dev_set.append(dev)\n",
        "    categories_test_set.append(test)"
      ],
      "metadata": {
        "id": "nlFtb4Swaq4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_split_chitchat_dataset():\n",
        "  \n",
        "  global chitchat_train_set, chitchat_dev_set, chitchat_test_set\n",
        "  \n",
        "  data = pd.DataFrame(columns = [\"Question\", \"Answer\", \"Source\", \"Metadata\"])\n",
        "  files = [\"English_Professional.tsv\", \"English_Friendly.tsv\", \n",
        "           \"English_Witty.tsv\", \"English_Caring.tsv\", \"English_Enthusiastic.tsv\"]\n",
        "  \n",
        "  for file in files:\n",
        "    path = drive_root_path + 'chitchat/' + file\n",
        "    df = pd.read_csv(path, sep='\\t')\n",
        "    data = pd.concat([data, df])\n",
        "  \n",
        "  data = data[[\"Question\", \"Answer\"]].copy()\n",
        "\n",
        "  data.rename(columns = {'Question':'question', 'Answer':'answer'}, inplace = True)\n",
        "  data['question'] = data['question'].apply(clean_question)\n",
        "  data['answer']   = data['answer'].apply(clean_answer)\n",
        "  chitchat_train_set, chitchat_dev_set, chitchat_test_set = data_split(data)"
      ],
      "metadata": {
        "id": "dyH5i0NQls38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Shuffle Chitchat Dataset"
      ],
      "metadata": {
        "id": "bVOcgrlW5btP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_dataset():\n",
        "  global chitchat_train_set, chitchat_dev_set, chitchat_test_set\n",
        "  chitchat_train_set = chitchat_train_set.sample(frac=1, random_state=1).reset_index(drop=True)\n",
        "  chitchat_dev_set   = chitchat_dev_set.sample(frac=1, random_state=1).reset_index(drop=True)\n",
        "  chitchat_test_set  = chitchat_test_set.sample(frac=1, random_state=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "kShJVqxYp8Op"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Data after processing\n"
      ],
      "metadata": {
        "id": "xtCOOqRApjQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_split_chitchat_dataset()\n",
        "shuffle_dataset()\n",
        "load_split_amazon_dataset()"
      ],
      "metadata": {
        "id": "Yct8vnyGo-YJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, dev, test = load_new_dataset()"
      ],
      "metadata": {
        "id": "HtwO26h_xvSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = train['question'], train['answer']\n",
        "x_dev, y_dev = dev['question'], dev['answer']\n",
        "x_test, y_test = test['question'], test['answer']"
      ],
      "metadata": {
        "id": "McmRKBlpynL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chit Chat Model\n"
      ],
      "metadata": {
        "id": "12VZoilRNG8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chitchat_x_train, chitchat_y_train = chitchat_train_set['question'], chitchat_train_set['answer']\n",
        "chitchat_x_dev, chitchat_y_dev     = chitchat_dev_set['question'], chitchat_dev_set['answer']\n",
        "chitchat_x_test, chitchat_y_test   = chitchat_test_set['question'], chitchat_test_set['answer']"
      ],
      "metadata": {
        "id": "NnqNs1XSqz-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clothing Model"
      ],
      "metadata": {
        "id": "DH67tIW7NLbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clothing_x_train, clothing_y_train = categories_train_set[0]['question'], categories_train_set[0]['answer']\n",
        "clothing_x_dev, clothing_y_dev     = categories_dev_set[0]['question'], categories_dev_set[0]['answer']\n",
        "clothing_x_test, clothing_y_test   = categories_test_set[0]['question'], categories_test_set[0]['answer']"
      ],
      "metadata": {
        "id": "LbNbbBHLNBuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Health Model\n"
      ],
      "metadata": {
        "id": "Z4HAzoD46M3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "health_x_train, health_y_train = categories_train_set[1]['question'], categories_train_set[1]['answer']\n",
        "health_x_dev, health_y_dev     = categories_dev_set[1]['question'], categories_dev_set[1]['answer']\n",
        "health_x_test, health_y_test   = categories_test_set[1]['question'], categories_test_set[1]['answer']"
      ],
      "metadata": {
        "id": "MNB0Xqe7NEPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sports Model"
      ],
      "metadata": {
        "id": "guJQzrgY6O6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sport_x_train, sport_y_train = categories_train_set[2]['question'], categories_train_set[2]['answer']\n",
        "sport_x_dev, sport_y_dev     = categories_dev_set[2]['question'], categories_dev_set[2]['answer']\n",
        "sport_x_test, sport_y_test   = categories_test_set[2]['question'], categories_test_set[2]['answer']"
      ],
      "metadata": {
        "id": "g9qNhFb9NE5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Words Vectorization & Embedding**"
      ],
      "metadata": {
        "id": "vm8Cq9zJPZRn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "BBVuWV_bOD4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.io import write_file, read_file\n",
        "import gc\n",
        "import os"
      ],
      "metadata": {
        "id": "LESkMr4lPqjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Constants"
      ],
      "metadata": {
        "id": "B7GGTGdwOKgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SAVE_DIR = '/content/drive/My Drive/Colab Notebooks/chatbot project/SuperAgentModel/'\n",
        "current_model = 'ClothingModel'\n",
        "VOCAB_SIZE = 1\n",
        "if current_model == 'ClothingModel':\n",
        "  VOCAB_SIZE = 11929\n",
        "elif current_model == 'ChitChatModel':\n",
        "  VOCAB_SIZE = 2820\n",
        "elif current_model == 'HealthModel':\n",
        "  VOCAB_SIZE = 36059\n",
        "elif current_model == 'SportsModel2':\n",
        "  VOCAB_SIZE = 54202\n",
        "elif current_model == 'QAModel':\n",
        "  VOCAB_SIZE = 26817\n",
        "\n",
        "BATCH_SIZE = 64"
      ],
      "metadata": {
        "id": "-dYHn0yNOKLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorization"
      ],
      "metadata": {
        "id": "h59vlbinSorS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vectorize_layer(x_train, y_train):\n",
        "  vectorize_layer = tf.keras.layers.TextVectorization(standardize=None)\n",
        "  vectorize_layer.adapt(pd.concat([x_train, y_train]))\n",
        "  VOCAB_SIZE = vectorize_layer.vocabulary_size()\n",
        "  gc.collect()\n",
        "  return vectorize_layer, VOCAB_SIZE"
      ],
      "metadata": {
        "id": "5jmk9G4gOUVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_seq2se2_data(x, y, vectorize_layer):\n",
        "\n",
        "  enc_input_data = vectorize_layer(x)\n",
        "\n",
        "  dec_input_data = vectorize_layer(y)\n",
        "  dec_output_data = dec_input_data[:, 1:]\n",
        "  \n",
        "  dec_output_data = tf.concat([dec_output_data, tf.zeros((dec_output_data.shape[0], 1), dtype=tf.int64)], 1)\n",
        "  gc.collect()\n",
        "  return enc_input_data, dec_input_data, dec_output_data"
      ],
      "metadata": {
        "id": "tiLDHXUYOWEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Processed Data"
      ],
      "metadata": {
        "id": "58pFQT6RwVO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_as_batches(foldername, np_array, batch_size):\n",
        "  num_batches = np_array.shape[0] // batch_size\n",
        "  dir = SAVE_DIR + foldername + '/'\n",
        "  for i in range(num_batches):\n",
        "    np.save(dir + str(i) + '.npy', np_array[i*batch_size:(i+1)*batch_size, :])\n",
        "  if(num_batches*batch_size < np_array.shape[0]):\n",
        "    np.save(dir + str(num_batches) + '.npy', np_array[num_batches*batch_size:, :])"
      ],
      "metadata": {
        "id": "EVR9MKKMwTXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save(foldername, np_array):\n",
        "  path = SAVE_DIR + foldername + '/0.npy'\n",
        "  np.save(path, np_array)"
      ],
      "metadata": {
        "id": "gsdZvOOcJdf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "def save_vectorizer(vectorizer):\n",
        "  path = SAVE_DIR + current_model + '/vectorizer.pkl'\n",
        "  pickle.dump({'config': vectorizer.get_config(),\n",
        "               'weights': vectorizer.get_weights()}\n",
        "              , open(path, \"wb\"))"
      ],
      "metadata": {
        "id": "7hCvSOsWfufS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  vectorize_layer, vocab_size = create_vectorize_layer(health_x_train, health_y_train)\n"
      ],
      "metadata": {
        "id": "fCorpA3eUugX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(foldername, x_train, y_train, x_dev, y_dev, x_test, y_test):\n",
        "\n",
        "  vectorize_layer, vocab_size = create_vectorize_layer(x_train, y_train)\n",
        "  print(foldername)\n",
        "  print(vocab_size)\n",
        "\n",
        "  save_vectorizer(vectorize_layer)\n",
        "\n",
        "  enc_input_data, dec_input_data, dec_output_data = get_seq2se2_data(x_train,\n",
        "                                                                     y_train, \n",
        "                                                                     vectorize_layer)\n",
        "  \n",
        "  val_enc_input_data, val_dec_input_data, val_dec_output_data = get_seq2se2_data(x_dev, \n",
        "                                                                                 y_dev, \n",
        "                                                                                 vectorize_layer)\n",
        "  \n",
        "  test_enc_input_data, test_dec_input_data, test_dec_output_data = get_seq2se2_data(x_test, \n",
        "                                                                                 y_test, \n",
        "                                                                                 vectorize_layer)\n",
        "\n",
        "  save_as_batches(foldername + '/dec_output_data', dec_output_data, BATCH_SIZE)\n",
        "  save_as_batches(foldername + '/dec_input_data', dec_input_data, BATCH_SIZE)\n",
        "  save_as_batches(foldername + '/enc_input_data', enc_input_data, BATCH_SIZE)\n",
        "\n",
        "  save(foldername + '/val_dec_output_data', val_dec_output_data)\n",
        "  save(foldername + '/val_dec_input_data', val_dec_input_data)\n",
        "  save(foldername + '/val_enc_input_data', val_enc_input_data)\n",
        "\n",
        "  save(foldername + '/test_dec_output_data', test_dec_output_data)\n",
        "  save(foldername + '/test_dec_input_data', test_dec_input_data)\n",
        "  save(foldername + '/test_enc_input_data', test_enc_input_data)"
      ],
      "metadata": {
        "id": "-1xwDsgETVZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_model('ChitChatModel', chitchat_x_train, chitchat_y_train, chitchat_x_dev, \n",
        "           chitchat_y_dev, chitchat_x_test, chitchat_y_test)\n",
        "save_model('ClothingModel', clothing_x_train, clothing_y_train, clothing_x_dev, \n",
        "           clothing_y_dev, clothing_x_test, clothing_y_test)\n",
        "save_model('HealthModel', health_x_train, health_y_train, health_x_dev, \n",
        "           health_y_dev, health_x_test, health_y_test)\n",
        "save_model('SportsModel', sport_x_train, sport_y_train, sport_x_dev, \n",
        "           sport_y_dev, sport_x_test, sport_y_test)"
      ],
      "metadata": {
        "id": "qFoMk9xiUm68",
        "outputId": "a38c0f12-95a8-4955-ff6d-ae5301ef00ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HealthModel\n",
            "36059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_model('QAModel', x_train, y_train, x_dev, y_dev, x_test, y_test)"
      ],
      "metadata": {
        "id": "V_wWnmEvy5D1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69d454c8-cfb6-452e-fcf0-f11589801c80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QAModel\n",
            "26817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Processed Data"
      ],
      "metadata": {
        "id": "rDkqt-Nk9EeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, input_folder1, input_folder2, output_folder, batch_size=64):\n",
        "        self.input_folder1 = input_folder1\n",
        "        self.input_folder2 = input_folder2\n",
        "        self.output_folder = output_folder\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        # assuming there is nothing in the folders other than the preprocessed data, and all folders have the same number of files\n",
        "        return len(os.listdir(SAVE_DIR + self.output_folder))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        enc_input = np.load(SAVE_DIR + self.input_folder1 + '/' + str(index) + '.npy')\n",
        "        dec_input = np.load(SAVE_DIR + self.input_folder2 + '/' + str(index) + '.npy')\n",
        "        dec_output = np.load(SAVE_DIR + self.output_folder + '/' + str(index) + '.npy')\n",
        "        return [enc_input, dec_input], dec_output"
      ],
      "metadata": {
        "id": "YSO5aOBQAlnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCOnJkge87Li"
      },
      "outputs": [],
      "source": [
        "def load(foldername):\n",
        "  path = SAVE_DIR + foldername + '/0.npy'\n",
        "  return np.load(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWZNxAGgKQZC"
      },
      "outputs": [],
      "source": [
        "val_dec_output_data = load(current_model + '/val_dec_output_data')\n",
        "val_dec_input_data = load(current_model + '/val_dec_input_data')\n",
        "val_enc_input_data = load(current_model + '/val_enc_input_data')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dec_output_data = load(current_model + '/test_dec_output_data')\n",
        "test_dec_input_data = load(current_model + '/test_dec_input_data')\n",
        "test_enc_input_data = load(current_model + '/test_enc_input_data')"
      ],
      "metadata": {
        "id": "JaE0k8wuRUuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dec_output_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZ38vuKW2cJC",
        "outputId": "266777ad-1c6b-4d23-ef3a-b5c8b6891e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2204, 187)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayWHKOX3Q59Z"
      },
      "source": [
        "# **Training Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2h4eYvwRRBBV"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RU8eJL0GQi4g"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Dropout\n",
        "from tensorflow.keras.layers import GRU, LSTM, Bidirectional, Concatenate\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcgZXpudQ5IH"
      },
      "source": [
        "### Custom Evaluation Functions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bleu_score(y_true, y_pred):\n",
        "  return sentence_bleu(y_true, y_pred, smoothing_function=SmoothingFunction().method1)"
      ],
      "metadata": {
        "id": "wW7yPN3_Q4pY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MNuBvihdPBl"
      },
      "source": [
        "### Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3RM2U8mRDid"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_SIZE = 200\n",
        "UNITS = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding Layer"
      ],
      "metadata": {
        "id": "NsEgfBXI9o7z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GloVe Layer"
      ],
      "metadata": {
        "id": "xqBmSdvt-OW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enc_embedding_layer = glove_model.get_keras_embedding()\n",
        "dec_embedding_layer = glove_model.get_keras_embedding()"
      ],
      "metadata": {
        "id": "f_PwFmTu-zwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3zIRa-I1j_x"
      },
      "source": [
        "#### Downloading Glove Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dae-c-QRVXhX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f43923c1-d007-44f4-c4f8-0ad8899c3129"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-10 12:25:11--  http://nlp.stanford.edu/data/glove.42B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.42B.300d.zip [following]\n",
            "--2022-09-10 12:25:11--  https://nlp.stanford.edu/data/glove.42B.300d.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.42B.300d.zip [following]\n",
            "--2022-09-10 12:25:11--  https://downloads.cs.stanford.edu/nlp/data/glove.42B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1877800501 (1.7G) [application/zip]\n",
            "Saving to: ‘glove.42B.300d.zip’\n",
            "\n",
            "glove.42B.300d.zip  100%[===================>]   1.75G  5.12MB/s    in 5m 54s  \n",
            "\n",
            "2022-09-10 12:31:05 (5.05 MB/s) - ‘glove.42B.300d.zip’ saved [1877800501/1877800501]\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-21ubuntu1.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 20 not upgraded.\n",
            "Archive:  glove.42B.300d.zip\n",
            "  inflating: glove.42B.300d.txt      \n"
          ]
        }
      ],
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.42B.300d.zip\n",
        "!apt install unzip\n",
        "!unzip \"glove.42B.300d.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpUP-_uyIZDL",
        "outputId": "d2d15753-6f89-44b1-c2a6-76a7f3968bd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'glove.42B.300d.txt', 'drive', 'glove.42B.300d.zip', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "import os\n",
        "os.listdir()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl0iKOj71pjn"
      },
      "source": [
        "#### Convert Glove Embedding to Word2Vec Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNvMFEolJuSi"
      },
      "outputs": [],
      "source": [
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "glove2word2vec(glove_input_file=\"glove.42B.300d.txt\", word2vec_output_file=\"gensim_glove_vectors.txt\")\n",
        "\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "glove_model = KeyedVectors.load_word2vec_format(\"gensim_glove_vectors.txt\", binary=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normal Embedding Layer"
      ],
      "metadata": {
        "id": "NM86pnIh_Fgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enc_embedding_layer = Embedding(VOCAB_SIZE, EMBEDDING_SIZE, mask_zero=True)\n",
        "dec_embedding_layer = Embedding(VOCAB_SIZE, EMBEDDING_SIZE, mask_zero=True)"
      ],
      "metadata": {
        "id": "9TdwfiKK-FJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G7bpG85CLoN"
      },
      "source": [
        "##LSTM Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3qTT4wkCSJ2"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTtLNhebCSJ3"
      },
      "outputs": [],
      "source": [
        "enc_input = Input(shape=(None,))\n",
        "\n",
        "enc_embedding = enc_embedding_layer(enc_input)\n",
        "enc_outputs, state_h, state_c = LSTM(UNITS, return_state=True,\n",
        "                                     kernel_regularizer='l2')(enc_embedding)\n",
        "enc_states = [state_h, state_c]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCg5BCAACSJ4"
      },
      "source": [
        "###  Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2SorjqOCSJ5"
      },
      "outputs": [],
      "source": [
        "dec_input = Input(shape=(None,))\n",
        "\n",
        "dec_embedding = dec_embedding_layer(dec_input)\n",
        "dec_outputs, _, _  = LSTM(UNITS, return_state=True, \n",
        "                          return_sequences=True,\n",
        "                          kernel_regularizer='l2')(dec_embedding, initial_state=enc_states)\n",
        "dropout = Dropout(0.5)(dec_outputs) \n",
        "output = Dense(VOCAB_SIZE, activation='softmax')(dropout)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WMNvNpiRUiq"
      },
      "source": [
        "## Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcx6Oy_gRUGk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be4fc1df-21f6-4461-b049-02eb398e23b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"health_model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, None, 200)    2385800     ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, None, 200)    2385800     ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, 100),        120400      ['embedding_2[0][0]']            \n",
            "                                 (None, 100),                                                     \n",
            "                                 (None, 100)]                                                     \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 100),  120400      ['embedding_3[0][0]',            \n",
            "                                 (None, 100),                     'lstm_2[0][1]',                 \n",
            "                                 (None, 100)]                     'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, None, 100)    0           ['lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, None, 11929)  1204829     ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6,217,229\n",
            "Trainable params: 6,217,229\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Model([enc_input, dec_input], output, name='health_model')\n",
        "opt = Adam(learning_rate=0.01)\n",
        "model.compile(optimizer=opt, loss=SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBulUBn2SpgU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6077fc2a-eabc-4524-b10b-592498c51f0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"health_model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, None, 200)    2385800     ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, None, 200)    2385800     ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, 100),        120400      ['embedding_2[0][0]']            \n",
            "                                 (None, 100),                                                     \n",
            "                                 (None, 100)]                                                     \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 100),  120400      ['embedding_3[0][0]',            \n",
            "                                 (None, 100),                     'lstm_2[0][1]',                 \n",
            "                                 (None, 100)]                     'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, None, 100)    0           ['lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, None, 11929)  1204829     ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6,217,229\n",
            "Trainable params: 6,217,229\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "path = SAVE_DIR + 'checkpoints/health_model'\n",
        "model = load_model(path)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P21wmZQVRYfv"
      },
      "outputs": [],
      "source": [
        "data_generator = DataGenerator(current_model + '/enc_input_data', \n",
        "                               current_model + '/dec_input_data', \n",
        "                               current_model + '/dec_output_data')\n",
        "\n",
        "save_callback = ModelCheckpoint(SAVE_DIR + 'checkpoints/health_model')\n",
        "\n",
        "history = model.fit(x=data_generator,\n",
        "                    epochs=30, \n",
        "                    validation_data=([val_enc_input_data, val_dec_input_data],\n",
        "                                                          val_dec_output_data), \n",
        "                    callbacks=[save_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ooq6ZTetRpLs"
      },
      "outputs": [],
      "source": [
        "history"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Testing Model**"
      ],
      "metadata": {
        "id": "OHRQR1ETL_Ev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate([val_enc_input_data, val_dec_input_data], val_dec_output_data, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOS0Tc4WMiiv",
        "outputId": "0aa40328-005b-432d-d480-d234d29437a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 5s 71ms/step - loss: 0.6237 - accuracy: 0.3069\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6237284541130066, 0.30688631534576416]"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate([test_enc_input_data, test_dec_input_data], test_dec_output_data, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "36lRC1wYL-0g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "636e9c5e-6280-496d-8760-087e22fb845e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 5s 74ms/step - loss: 0.5884 - accuracy: 0.3130\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5883707404136658, 0.313035249710083]"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inference Model**"
      ],
      "metadata": {
        "id": "bnJ_4Qd9CkIJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Vectorized Layer\n"
      ],
      "metadata": {
        "id": "qI2B94c7CG18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "def load_vectorizer(folder_name):\n",
        "  path = SAVE_DIR + folder_name +'vectorizer.pkl'\n",
        "  from_disk = pickle.load(open(path, \"rb\"))\n",
        "  vectorizer = TextVectorization.from_config(from_disk['config'])\n",
        "  vectorizer.set_weights(from_disk['weights'])\n",
        "  return vectorizer"
      ],
      "metadata": {
        "id": "Rkug6E6KhcDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM "
      ],
      "metadata": {
        "id": "zPM_qd2VHma0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_encoder_decoder_model_lstm(model):\n",
        "  # Get Model's Layers\n",
        "  enc_input = model.input[0]\n",
        "  dec_input = model.input[1]\n",
        "  enc_embedding_layer = model.get_layer(index=2)\n",
        "  dec_embedding_layer = model.get_layer(index=3)\n",
        "  enc_layer = model.get_layer(index=4)\n",
        "  dec_layer = model.get_layer(index=5)\n",
        "  dec_dense_layer = model.get_layer(index=-1)\n",
        "\n",
        "  # Model's Parameters\n",
        "  EMBEDDING_SIZE = dec_embedding_layer.output.shape[-1]\n",
        "  UNITS = dec_layer.output[0].shape[-1]\n",
        "\n",
        "  # Encoder Model\n",
        "  _ , enc_state_h, enc_state_c = enc_layer.output\n",
        "  enc_model = Model(enc_input, [enc_state_h, enc_state_c], \n",
        "                  name='encoder_inference_model')\n",
        "  \n",
        "  # Decoder Model\n",
        "  dec_embedding = dec_embedding_layer.output \n",
        "  dec_state_input_h = Input(shape=(UNITS,), name='decoder_input_state_h')\n",
        "  dec_state_input_c = Input(shape=(UNITS,), name='decoder_input_state_c')\n",
        "  dec_outputs, dec_state_output_h, dec_state_output_c = dec_layer(dec_embedding, \n",
        "                                                                      initial_state=[dec_state_input_h, dec_state_input_c])\n",
        "  output = dec_dense_layer(dec_outputs)\n",
        "  dec_model = Model([dec_input, dec_state_input_h, dec_state_input_c], \n",
        "                    [output, dec_state_output_h, dec_state_output_c], \n",
        "                    name='decoder_inference_model')\n",
        "  \n",
        "  return enc_model, dec_model"
      ],
      "metadata": {
        "id": "gyz-j9BluRak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Loop"
      ],
      "metadata": {
        "id": "IRwo7u78Vyiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "START_TOKEN = 'START_'\n",
        "END_TOKEN = '_END'\n",
        "MAX_ANSWER_LEN = 200"
      ],
      "metadata": {
        "id": "STdvndgRwBSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "CMdruxmuPuE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer(question, enc_model, dec_model, vectorizer):\n",
        "  vectorized_question = np.reshape(vectorizer(question).numpy(), (1, -1))\n",
        "  print(f'question: {question}')\n",
        "  state_h, state_c = enc_model.predict(vectorized_question)\n",
        "\n",
        "  empty_target_seq = np.reshape(vectorizer(START_TOKEN).numpy(), (1, -1))\n",
        "  stop_condition = False\n",
        "  decoded_translation = 'answer : '\n",
        "  while not stop_condition:\n",
        "\n",
        "      dec_outputs, dec_state_h, dec_state_c = dec_model.predict([empty_target_seq, state_h, state_c])         \n",
        "\n",
        "      sampled_word_index = np.argmax(dec_outputs[0, -1, :])\n",
        "      sampled_word = vectorizer.get_vocabulary()[sampled_word_index]\n",
        "      if sampled_word != END_TOKEN:\n",
        "        decoded_translation += f' {sampled_word}'\n",
        "      \n",
        "      if sampled_word == END_TOKEN or len(decoded_translation.split()) > MAX_ANSWER_LEN:\n",
        "          stop_condition = True\n",
        "\n",
        "      empty_target_seq = np.zeros((1, 1))\n",
        "      empty_target_seq[0, 0] = sampled_word_index\n",
        "      state_h, state_c = dec_state_h, dec_state_c\n",
        "\n",
        "  return decoded_translation"
      ],
      "metadata": {
        "id": "CCWwEOZ1PT75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(answer('skin care products?'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvPdD_lchJKn",
        "outputId": "eebf70bf-d9b1-485c-aadf-e4f4c7b5d1e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question: skin care products?\n",
            "answer :  a lot  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a  a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JnzSqlJppW_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reranking Model**"
      ],
      "metadata": {
        "id": "NMAuk_dawoIH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7bQlpfQ3PHI"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0YojJbw3PHJ"
      },
      "source": [
        "### Global Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJZXK4Df3PHK"
      },
      "outputs": [],
      "source": [
        "drive_root_path = '/content/drive/My Drive/Colab Notebooks/chatbot project/Chatbot/'\n",
        "test_dev_ratio = 0.1\n",
        "gener_examples = 20000\n",
        "train_set = dev_set = test_set = pd.DataFrame(columns=['question', 'label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPTLwJC13PHL"
      },
      "source": [
        "## Data load and Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvBGw_TY3PHL"
      },
      "source": [
        "### Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlCvCm7n3PHL"
      },
      "outputs": [],
      "source": [
        "def data_split(dataset):\n",
        "\n",
        "  global train_set, dev_set, test_set\n",
        "\n",
        "  train, test = train_test_split(dataset, test_size=test_dev_ratio, \n",
        "                                         random_state=0)\n",
        "\n",
        "  test, dev = train_test_split(test, test_size=0.5, \n",
        "                                         random_state=0) \n",
        "  \n",
        "  train_set = pd.concat([train_set, train])\n",
        "  dev_set   = pd.concat([dev_set, dev])\n",
        "  test_set  = pd.concat([test_set, test])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ievIdCWJ3PHL"
      },
      "source": [
        "### Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPNY6krN3PHL"
      },
      "outputs": [],
      "source": [
        "def load_split_amazon_dataset():\n",
        "\n",
        "  geners = ['qa_Clothing_Shoes_and_Jewelry.json.gz',\n",
        "            'qa_Health_and_Personal_Care.json.gz',\n",
        "            'qa_Sports_and_Outdoors.json.gz']\n",
        "\n",
        "  for i, gener in enumerate(geners):\n",
        "\n",
        "    df = getDF(drive_root_path + gener)\n",
        "\n",
        "    df = df[['question']]\n",
        "    df['label'] = i\n",
        "\n",
        "    data_split(df)\n",
        "    print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQvPo2fN3PHL"
      },
      "outputs": [],
      "source": [
        "def load_split_chitchat_dataset():\n",
        "  data = pd.DataFrame(columns = [\"Question\", \"Answer\", \"Source\", \"Metadata\"])\n",
        "  files = [\"English_Professional.tsv\", \"English_Friendly.tsv\", \"English_Witty.tsv\", \"English_Caring.tsv\",   \"English_Enthusiastic.tsv\"]\n",
        "  \n",
        "  for file in files:\n",
        "    path = drive_root_path + 'chitchat/' + file\n",
        "    df = pd.read_csv(path, sep='\\t')\n",
        "    data = pd.concat([data, df])\n",
        "  \n",
        "  data = data[[\"Question\"]].copy()\n",
        "  print('length of dataset = ', len(data))\n",
        "  data.rename(columns = {'Question':'question'}, inplace = True)\n",
        "  data['label'] = 3\n",
        "  data_split(data)\n",
        "  print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lgooUVi3PHM"
      },
      "source": [
        "### Shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysTfr76g3PHM"
      },
      "outputs": [],
      "source": [
        "def shuffle_dataset():\n",
        "  global train_set, dev_set, test_set\n",
        "\n",
        "  train_set = train_set.sample(frac=1, random_state=1).reset_index(drop=True)\n",
        "  dev_set   = dev_set.sample(frac=1, random_state=1).reset_index(drop=True)\n",
        "  test_set  = test_set.sample(frac=1, random_state=1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pPR6bBR3PHM"
      },
      "source": [
        "## Generate Data after processing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qKiOERs3PHM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a072828b-73b5-4a1e-ecea-cd13fb2e97b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset =  48965\n",
            "                   question  label\n",
            "0          Do you get hurt?      3\n",
            "1      Do you have fingers?      3\n",
            "2       Do you ever breathe      3\n",
            "3         Do you masticate?      3\n",
            "4         Can you throw up?      3\n",
            "...                     ...    ...\n",
            "9788    I'm tired from work      3\n",
            "9789    I'm totally drained      3\n",
            "9790  I'm totally exhausted      3\n",
            "9791                  Zzzzz      3\n",
            "9792          I'm so sleepy      3\n",
            "\n",
            "[48965 rows x 2 columns]\n",
            "                                                question  label\n",
            "0      You bought level one . Will you buy the next l...      0\n",
            "1                    Will you buy the next level edition      0\n",
            "2                                  Did you learn Chinese      0\n",
            "3      Do you see words written as well as hearing th...      0\n",
            "4                           does it work with windows 8?      0\n",
            "...                                                  ...    ...\n",
            "22063  So the watch is waterproof, but is this leathe...      0\n",
            "22064  What is the difference between this watch at $...      0\n",
            "22065  How long does it take to fully charge the batt...      0\n",
            "22066  Can the display be flipped for left handed peo...      0\n",
            "22067  Hello, can we text or write email with this Sm...      0\n",
            "\n",
            "[22068 rows x 2 columns]\n",
            "                                                question  label\n",
            "0                      which model Norelcos does it fit?      1\n",
            "1      What replacement blades do I use for my 5801XL...      1\n",
            "2                     are these made by philips norelco?      1\n",
            "3                  I have a philips HQ 6695 does it fit?      1\n",
            "4      I have a pt 730 and I would like to get replac...      1\n",
            "...                                                  ...    ...\n",
            "80491  Do the lights rotate by it self? Or do I have ...      1\n",
            "80492  I see that it comes with an adapter but in the...      1\n",
            "80493  does this diffuser automatically shut off when...      1\n",
            "80494  Do you have to have the LED light on? Or can y...      1\n",
            "80495                            is the black available?      1\n",
            "\n",
            "[80496 rows x 2 columns]\n",
            "                                                 question  label\n",
            "0                               compatible with windows7?      2\n",
            "1                  Can this program print 7.5 minute maps      2\n",
            "2       does this come with gps antena tat plugs into ...      2\n",
            "3       DeLorme is notorious for poor proprietary maps...      2\n",
            "4                         does topo 10 run on windows 8.1      2\n",
            "...                                                   ...    ...\n",
            "146886  is it possible to buy it from Italy?! Because ...      2\n",
            "146887  f it's possible I would like to know the dimen...      2\n",
            "146888  Are you planning to sell the Stainless steel m...      2\n",
            "146889  Can the chrome layer peels off? How long is it...      2\n",
            "146890            What is the weight limit for this pole?      2\n",
            "\n",
            "[146891 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "load_split_chitchat_dataset()\n",
        "load_split_amazon_dataset()\n",
        "shuffle_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBB6XnFn3PHM"
      },
      "outputs": [],
      "source": [
        "x_train, y_train = train_set['question'], train_set['label']\n",
        "x_dev, y_dev     = dev_set['question'], dev_set['label']\n",
        "x_test, y_test   = test_set['question'], test_set['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model\n"
      ],
      "metadata": {
        "id": "iW2PKLRX7Oef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "0lA1mGoc1e9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir = '/content/drive/My Drive/Colab Notebooks/chatbot project/'\n",
        "clothing_model = load_model(dir + 'SuperAgentModel2/checkpoints/cmodel_3')\n",
        "health_model = load_model(dir + 'SuperAgentModel/checkpoints/health_model')\n",
        "sports_model = load_model(dir + 'SuperAgentModel2/checkpoints/smodel_7')\n",
        "chichat_model = load_model(dir + 'SuperAgentModel/checkpoints/chitchat_lstm_150_300_0.01') "
      ],
      "metadata": {
        "id": "Z6Vr4bIeyR84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(question):\n",
        "  text_clf = Pipeline([('vect', CountVectorizer()),\n",
        "                      ('tfidf', TfidfTransformer()),\n",
        "                      ('clf', MultinomialNB()),])\n",
        "\n",
        "  text_clf = text_clf.fit(x_train, y_train.tolist())\n",
        "  predicted = text_clf.predict([question])\n",
        "  predicted = predicted[0]\n",
        "\n",
        "  if predicted == 0:\n",
        "    print(\"Clothing Model :\")\n",
        "    vectorizer = load_vectorizer(\"ClothingModel/\")\n",
        "    model = clothing_model\n",
        "  elif predicted == 1:\n",
        "    print(\"Health Model :\")\n",
        "    vectorizer = load_vectorizer(\"HealthModel/\")\n",
        "    model = health_model\n",
        "  elif predicted == 2:\n",
        "    print(\"Sports Model :\")\n",
        "    vectorizer = load_vectorizer(\"SportsModel/\")\n",
        "    model = sports_model\n",
        "  elif predicted == 3:\n",
        "    print(\"Chitchat Model :\")\n",
        "    vectorizer = load_vectorizer(\"ChitChatModel/\")\n",
        "    model = chichat_model\n",
        "  \n",
        "  enc_model, dec_model = get_encoder_decoder_model_lstm(model)\n",
        "  print(answer(question, enc_model, dec_model, vectorizer))"
      ],
      "metadata": {
        "id": "rjB08-UOoV3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot(\"how are you\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHZhTnnrx25e",
        "outputId": "9f3b37ea-f711-4741-c36d-0292416eb3cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports Model :\n",
            "question: how are you\n",
            "answer :  i would not say it is a good question\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot(\"what is the size of this jacket\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1pGDwJcUGCZ",
        "outputId": "e3dfe71f-8657-42bf-e3c2-df708b55f7db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports Model :\n",
            "question: what is the size of this jacket\n",
            "answer :  i am not sure but i am not sure i would say it is a good question\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot(\"what are the best steps for a daily skincare routine\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ClF2ckSUMYG",
        "outputId": "2288229a-09f8-46d9-8465-51e70d759bc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health Model :\n",
            "question: what are the best steps for a daily skincare routine\n",
            "answer :  the this it START_ this off\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot(\"is potato good for kids\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyxPuFMtUT9f",
        "outputId": "faaee6d9-74e5-40de-a8d9-e8e7dbc5cbcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports Model :\n",
            "question: is potato good for kids\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 26 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa41f42da70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 27 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa41e7ee680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "answer :  yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot(\"nice to meet you\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZ5EpRtGUfeY",
        "outputId": "ce951b86-59ca-41f1-8edd-9f2361c2a3db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chitchat Model :\n",
            "question: nice to meet you\n",
            "answer :  nice to meet you too\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot(\"what is the best place for picnic\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djuUMjAnUkGU",
        "outputId": "0b39b3bb-7717-43a5-83b0-1ebc1b5305d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports Model :\n",
            "question: what is the best place for picnic\n",
            "answer :  i am not sure but i am not sure i would say it is a good question\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot(\"are you happy now\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opwpNSd5VvXQ",
        "outputId": "89e7e8e1-8e1b-4602-9ce1-16b647b19d7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chitchat Model :\n",
            "question: are you happy now\n",
            "answer :  i am a bot so kind of like a robot but without all the moving parts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot(\"tell me a joke\")"
      ],
      "metadata": {
        "id": "GfW80vw9V5dF",
        "outputId": "72b19427-7c0c-43de-a1ec-efc7c57eedad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chitchat Model :\n",
            "question: tell me a joke\n",
            "answer :  i do not really know any jokes\n"
          ]
        }
      ]
    }
  ]
}